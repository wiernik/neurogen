#!/usr/bin/env python3
"""
Convert a .csv file containing predictions to multiple .csv files (following the VCMNet format)

Example usage:

# Locally
python utils/convert_megvcm_predictions.py --predictions /home/engaclew/DATA/neurogen/L3_HIPAA_LENA_cleaned/chunks/eaf_an1/megvcm_predictions_eaf_an1.csv --chunks /home/engaclew/DATA/neurogen/L3_HIPAA_LENA_cleaned/chunks/eaf_an1/chunks_20250613_205715.csv --project /home/engaclew/neurogen/data/L3_HIPAA_LENA_cleaned --set eaf/an1"""
""""""

import argparse
import os
from email.contentmanager import raw_data_manager
from pathlib import Path
import pandas as pd
import json
import ast
from collections import Counter
from ChildProject.projects import ChildProject
from ChildProject.annotations import AnnotationManager
from tqdm import tqdm

label_mapping = {
    0: 'J', # junk
    1: 'N', # non-canonical
    2: 'C', # canonical
    3: 'L', # laughing
    4: 'Y', # cry
}

def aggregate_labels(labels):
    # If a segment contains a canonical syllable, we return CNS
    if 'C' in labels:
        return 'C'

    # We're sure that the segment does not contain any CNS
    # If it contains NCS, we return NCS
    if 'N' in labels:
        return 'N'

    # We're sure that the segment does not contain any CNS or NCS
    # We use majority voting
    counts = Counter(labels)
    max_count = counts.most_common(1)[0][1]
    tied_labels = [label for label, count in counts.items() if count == max_count]

    # If there's a tie, use priority order: CRY > LAU > JUN
    tiebreaker_order = ['Y', 'L', 'J']
    for label in tiebreaker_order:
        if label in tied_labels:
            return label



def main():
    parser = argparse.ArgumentParser(description="Convert CSV files to JSON format for Meg's VM")
    parser.add_argument('--predictions', required=True, help='Path to the .csv file containing predictions for the 500-ms chunks.')
    parser.add_argument('--chunks', required=True, help='Path to the child-project generated file which contains information about how segments have been cut.')
    parser.add_argument('--project', required=True, help='Path to ChildProject project (neurogen).')
    parser.add_argument('--set', choices=['eaf/an1', 'its', 'vtc'], required=True, help='If true, will save .csv at the 2-mn clip level')
    args = parser.parse_args()
    args.predictions = Path(args.predictions)
    args.chunks = Path(args.chunks)
    args.project = Path(args.project)

    # Load project
    proj = ChildProject(args.project)
    am = AnnotationManager(proj)
    am.read()

    # Read predictions of the vocal maturity classifier and chunks generated by child-project
    predictions = pd.read_csv(args.predictions, sep=',')
    chunks = pd.read_csv(args.chunks, sep=',')
    chunks.rename({'onset': 'clip_onset', 'offset': 'clip_offset'}, axis=1, inplace=True)

    # Extract probability for the predicted class
    predictions['probabilities'] = predictions['probabilities'].apply(ast.literal_eval)
    predictions['probability'] = predictions.apply(lambda row: row['probabilities'][row['predicted_label']], axis=1)

    # Drop logits, probabilities, and true_label (fake) columns
    predictions.drop(['logits', 'probabilities', 'true_label'], axis=1, inplace=True)

    # Retrieve clip_onset & clip_offset from id
    id_split = predictions['id'].str.rsplit('_', n=2, expand=True)
    predictions['recording_filename'] = id_split.iloc[:, 0] + '.wav'
    predictions['clip_onset'] = id_split.iloc[:, 1]
    predictions['clip_offset'] = id_split.iloc[:, 2]

    predictions['clip_onset'] = predictions['clip_onset'].astype('int64')
    predictions['clip_offset'] = predictions['clip_offset'].astype('int64')
    chunks['clip_onset'] = chunks['clip_onset'].astype('int64')
    chunks['clip_offset'] = chunks['clip_offset'].astype('int64')
    predictions = predictions.merge(
        chunks[['recording_filename', 'clip_onset', 'clip_offset', 'segment_onset', 'segment_offset']],
        on=['recording_filename', 'clip_onset', 'clip_offset'],
        how='left'
    )

    # Replace label by something more human friendly
    predictions['predicted_label'] = predictions['predicted_label'].map(label_mapping)

    # Aggregate 500-ms clips to have a single predicted_label per clip
    aggregated = predictions.groupby(['recording_filename', 'segment_onset', 'segment_offset'])[['predicted_label', 'probability']].agg(list).reset_index()
    aggregated = aggregated.rename(columns={'predicted_label': 'predicted_labels', 'probability': 'probabilities'})
    aggregated['predicted_label'] = aggregated['predicted_labels'].apply(aggregate_labels)
    aggregated['speaker_type'] = 'CHI'

    # Write files
    output_folder = args.project / 'annotations' / 'meg_vcm'
    if args.set == 'eaf/an1':
        # Read annotations to know what are the 2-mn clips that have been annotated
        annotated_clips = am.annotations[am.annotations['set'] == 'eaf/an1'][
            ['recording_filename', 'range_onset', 'range_offset']]
        (output_folder / 'raw_from_human_timestamps').mkdir(parents=True, exist_ok=True)
        (output_folder / 'converted_from_human_timestamps').mkdir(parents=True, exist_ok=True)
        for row, (recording_filename, range_onset, range_offset) in tqdm(annotated_clips.iterrows()):
            sub_data = aggregated[(aggregated.recording_filename == recording_filename) &
                                  (aggregated['segment_onset'] >= range_onset) &
                                  (aggregated['segment_offset'] <= range_offset)]

            # Write raw csv file with more information
            filename = f'{Path(recording_filename).stem}_{range_onset}_{range_offset}.csv'
            output_csv = output_folder / 'raw_from_human_timestamps' / filename
            csv_data = sub_data[['segment_onset', 'segment_offset', 'speaker_type', 'predicted_label', 'predicted_labels', 'probabilities']]
            csv_data.to_csv(output_csv, sep=',', index=False)

            # Write converted csv file in childproject format
            output_csv = output_folder / 'converted_from_human_timestamps' / filename
            csv_data = sub_data[['segment_onset', 'segment_offset', 'speaker_type', 'predicted_label']]
            csv_data.to_csv(output_csv, sep=',', index=False)
    else:
        recording_filenames = am.annotations[am.annotations['set'] == args.set]['recording_filename']
        (output_folder / f'raw_from_{args.set}').mkdir(parents=True, exist_ok=True)
        (output_folder / f'converted_from_{args.set}').mkdir(parents=True, exist_ok=True)
        for recording_filename in tqdm(recording_filenames):
            sub_data = aggregated[(aggregated.recording_filename == recording_filename)]

            # Write raw csv file with more information
            filename = f'{Path(recording_filename).stem}.csv'
            output_csv = output_folder / f'raw_from_{args.set}' / filename
            csv_data = sub_data[['segment_onset', 'segment_offset', 'speaker_type', 'predicted_label', 'predicted_labels', 'probabilities']]
            csv_data.to_csv(output_csv, sep=',', index=False)

            # Write converted csv file in childproject format
            output_csv = output_folder / f'converted_from_{args.set}' / filename
            csv_data = sub_data[['segment_onset', 'segment_offset', 'speaker_type', 'predicted_label']]
            csv_data.to_csv(output_csv, sep=',', index=False)

if __name__ == '__main__':
    main()